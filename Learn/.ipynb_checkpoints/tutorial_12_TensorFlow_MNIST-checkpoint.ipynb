{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using PyCall\n",
    "using MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST data\n",
    "The DataLoader API provided in \"examples/mnist_loader.jl\" has some simple code for loading the MNIST dataset, based on the MNIST.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader(1, [54326, 35307, 2472, 35050, 58036, 16266, 42206, 2510, 48789, 56003  â€¦  29012, 31611, 37827, 28561, 33811, 43415, 14913, 33969, 28068, 44406])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(Pkg.dir(\"TensorFlow\", \"examples\", \"mnist_loader.jl\"))\n",
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x00007f2b7cdac2f0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess=TensorFlow.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a softmax regression model\n",
    "##### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor placeholder_2:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=TensorFlow.placeholder(Float32)\n",
    "y_=TensorFlow.placeholder(Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W=TensorFlow.Variable(zeros(Float32,784,10))\n",
    "b=TensorFlow.Variable(zeros(Float32,10))\n",
    "\n",
    "TensorFlow.run(sess,TensorFlow.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predicted Class and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce_3:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=TensorFlow.nn.softmax(x*W+b)\n",
    "#cross_entropy=TensorFlow.reduce_mean(TensorFlow.nn.sparse_softmax_cross_entropy_with_logits(y,y_))\n",
    "cross_entropy = reduce_mean(-reduce_sum(y_ .* log(y), axis=[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note several differences from the Python version of the tutorial:\n",
    "\n",
    "* Python uses tf.matmul for matrix multiplication and * for element-wise multiplication of tensors in the computation graph. Julia uses * for matrix multiplication and .* for element-wise multiplication.\n",
    "\n",
    "* The reduction index for the loss term is 1 in the Python version, but the Julia API assumes 1-based indexing to be consistent with the rest of Julia and so 2 is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = train.minimize(train.GradientDescentOptimizer(.00001), cross_entropy)\n",
    "for i in 1:1000\n",
    "    batch = next_batch(loader, 100)\n",
    "    run(sess, train_step, Dict(x=>batch[1], y_=>batch[2]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = indmax(y, 2) .== indmax(y_, 2)\n",
    "accuracy=reduce_mean(cast(correct_prediction, Float32))\n",
    "testx, testy = load_test_set()\n",
    "\n",
    "println(run(sess, accuracy, Dict(x=>testx, y_=>testy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a multi-layer convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
