{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Image Classification with Pre-trained Imagenet CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is adapted from Caffe's iPython Notebook example. We use pre-trained CNN model converted from Caffe's Model Zoo. Specifically, we use bvlc_reference_caffenet, which is the same model used in Caffe's own iPython Notebook example.\n",
    "\n",
    "This notebook is located in * examples/ijulia/ilsvrc12 * under Mocha's source directory. If you want to run this example by yourself, you need to\n",
    "\n",
    "* Install IJulia.jl, which is a Julia backend for IPython. Of course, you also need to have Python and IPython installed.\n",
    "* Install Images.jl, which we will use to read image files in this example.\n",
    "* (Optional) Install Gadfly.jl, which will be used to plot the class probability prediction.\n",
    "* Download pre-trained CNN model. There is a shell script get-model.sh that you could run to download the pre-trained CNN model in HDF5 format converted from Caffe's original binary protocol buffer format.\n",
    "\n",
    "After all the preparation, you can start the notebook by executing the following command in this demo's source directory.\n",
    "\n",
    " _ jupyter notebook _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Convolutional Network\n",
    "We will use Mocha's native extension here to get faster convolution. If you prefer to disable it or use CUDA backend instead, please refer to Mocha's document for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n",
      " * CUDA       disabled by default\n",
      " * Native Ext disabled by default\n",
      "Mocha configured, continue loading module...\n",
      "DefaultBackend = Mocha.CPUBackend\n"
     ]
    }
   ],
   "source": [
    "using Mocha\n",
    "backend=Mocha.CPUBackend()\n",
    "Mocha.init(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define the network structure. This is directly adapted from Caffe's bvlc_reference_caffenet model definition. Please refer to Mocha's CIFAR-10 tutorial on how to translate Caffe's model definition to Mocha. This model takes 3-channel color images of size 256-by-256 and crop to take a 227-by-227 region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-08-16T16:56:56 | info | Mocha]: Constructing net imagenet on Mocha.CPUBackend...\n",
      "[2018-08-16T16:56:57 | info | Mocha]: Topological sorting 16 layers...\n",
      "[2018-08-16T16:56:57 | info | Mocha]: Setup layers...\n",
      "[2018-08-16T16:57:03 | info | Mocha]: Network constructed!\n",
      "************************************************************\n",
      "          NAME: imagenet\n",
      "       BACKEND: Mocha.CPUBackend\n",
      "  ARCHITECTURE: 16 layers\n",
      "............................................................\n",
      " *** Mocha.MemoryDataLayer(data)\n",
      "    Outputs ---------------------------\n",
      "          data: Blob(256 x 256 x 3 x 1)\n",
      "............................................................\n",
      " *** Mocha.CropLayer(crop)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(256 x 256 x 3 x 1)\n",
      "    Outputs ---------------------------\n",
      "       cropped: Blob(227 x 227 x 3 x 1)\n",
      "............................................................\n",
      " *** Mocha.ConvolutionLayer(conv1)\n",
      "    Inputs ----------------------------\n",
      "       cropped: Blob(227 x 227 x 3 x 1)\n",
      "    Outputs ---------------------------\n",
      "         conv1: Blob(55 x 55 x 96 x 1)\n",
      "............................................................\n",
      " *** Mocha.PoolingLayer(pool1)\n",
      "    Inputs ----------------------------\n",
      "         conv1: Blob(55 x 55 x 96 x 1)\n",
      "    Outputs ---------------------------\n",
      "         pool1: Blob(27 x 27 x 96 x 1)\n",
      "............................................................\n",
      " *** Mocha.LRNLayer(norm1)\n",
      "    Inputs ----------------------------\n",
      "         pool1: Blob(27 x 27 x 96 x 1)\n",
      "    Outputs ---------------------------\n",
      "         norm1: Blob(27 x 27 x 96 x 1)\n",
      "............................................................\n",
      " *** Mocha.ConvolutionLayer(conv2)\n",
      "    Inputs ----------------------------\n",
      "         norm1: Blob(27 x 27 x 96 x 1)\n",
      "    Outputs ---------------------------\n",
      "         conv2: Blob(27 x 27 x 256 x 1)\n",
      "............................................................\n",
      " *** Mocha.PoolingLayer(pool2)\n",
      "    Inputs ----------------------------\n",
      "         conv2: Blob(27 x 27 x 256 x 1)\n",
      "    Outputs ---------------------------\n",
      "         pool2: Blob(13 x 13 x 256 x 1)\n",
      "............................................................\n",
      " *** Mocha.LRNLayer(norm2)\n",
      "    Inputs ----------------------------\n",
      "         pool2: Blob(13 x 13 x 256 x 1)\n",
      "    Outputs ---------------------------\n",
      "         norm2: Blob(13 x 13 x 256 x 1)\n",
      "............................................................\n",
      " *** Mocha.ConvolutionLayer(conv3)\n",
      "    Inputs ----------------------------\n",
      "         norm2: Blob(13 x 13 x 256 x 1)\n",
      "    Outputs ---------------------------\n",
      "         conv3: Blob(13 x 13 x 384 x 1)\n",
      "............................................................\n",
      " *** Mocha.ConvolutionLayer(conv4)\n",
      "    Inputs ----------------------------\n",
      "         conv3: Blob(13 x 13 x 384 x 1)\n",
      "    Outputs ---------------------------\n",
      "         conv4: Blob(13 x 13 x 384 x 1)\n",
      "............................................................\n",
      " *** Mocha.ConvolutionLayer(conv5)\n",
      "    Inputs ----------------------------\n",
      "         conv4: Blob(13 x 13 x 384 x 1)\n",
      "    Outputs ---------------------------\n",
      "         conv5: Blob(13 x 13 x 256 x 1)\n",
      "............................................................\n",
      " *** Mocha.PoolingLayer(pool5)\n",
      "    Inputs ----------------------------\n",
      "         conv5: Blob(13 x 13 x 256 x 1)\n",
      "    Outputs ---------------------------\n",
      "         pool5: Blob(6 x 6 x 256 x 1)\n",
      "............................................................\n",
      " *** Mocha.InnerProductLayer(fc6)\n",
      "    Inputs ----------------------------\n",
      "         pool5: Blob(6 x 6 x 256 x 1)\n",
      "    Outputs ---------------------------\n",
      "           fc6: Blob(4096 x 1)\n",
      "............................................................\n",
      " *** Mocha.InnerProductLayer(fc7)\n",
      "    Inputs ----------------------------\n",
      "           fc6: Blob(4096 x 1)\n",
      "    Outputs ---------------------------\n",
      "           fc7: Blob(4096 x 1)\n",
      "............................................................\n",
      " *** Mocha.InnerProductLayer(fc8)\n",
      "    Inputs ----------------------------\n",
      "           fc7: Blob(4096 x 1)\n",
      "    Outputs ---------------------------\n",
      "           fc8: Blob(1000 x 1)\n",
      "............................................................\n",
      " *** Mocha.SoftmaxLayer(prob)\n",
      "    Inputs ----------------------------\n",
      "           fc8: Blob(1000 x 1)\n",
      "    Outputs ---------------------------\n",
      "          prob: Blob(1000 x 1)\n",
      "************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height, img_channels = (256, 256, 3)\n",
    "crop_size = (227, 227)\n",
    "batch_size = 1  # could be larger if you want to classify a bunch of images at a time\n",
    "\n",
    "layers = [\n",
    "  MemoryDataLayer(name=\"data\", tops=[:data], batch_size=batch_size,\n",
    "      transformers=[(:data, DataTransformers.Scale(scale=255)),\n",
    "                    (:data, DataTransformers.SubMean(mean_file=\"model/ilsvrc12_mean.hdf5\"))],\n",
    "      data = Array[zeros(img_width, img_height, img_channels, batch_size)])\n",
    "  CropLayer(name=\"crop\", tops=[:cropped], bottoms=[:data], crop_size=crop_size)\n",
    "  ConvolutionLayer(name=\"conv1\", tops=[:conv1], bottoms=[:cropped],\n",
    "      kernel=(11,11), stride=(4,4), n_filter=96, neuron=Neurons.ReLU())\n",
    "  PoolingLayer(name=\"pool1\", tops=[:pool1], bottoms=[:conv1],\n",
    "      kernel=(3,3), stride=(2,2), pooling=Pooling.Max())\n",
    "  LRNLayer(name=\"norm1\", tops=[:norm1], bottoms=[:pool1],\n",
    "      kernel=5, scale=0.0001, power=0.75)\n",
    "  ConvolutionLayer(name=\"conv2\", tops=[:conv2], bottoms=[:norm1],\n",
    "      kernel=(5,5), pad=(2,2), n_filter=256, n_group=2, neuron=Neurons.ReLU())\n",
    "  PoolingLayer(name=\"pool2\", tops=[:pool2], bottoms=[:conv2],\n",
    "      kernel=(3,3), stride=(2,2), pooling=Pooling.Max())\n",
    "  LRNLayer(name=\"norm2\", tops=[:norm2], bottoms=[:pool2],\n",
    "      kernel=5, scale=0.0001, power=0.75)\n",
    "  ConvolutionLayer(name=\"conv3\", tops=[:conv3], bottoms=[:norm2],\n",
    "      kernel=(3,3), pad=(1,1), n_filter=384, neuron=Neurons.ReLU())\n",
    "  ConvolutionLayer(name=\"conv4\", tops=[:conv4], bottoms=[:conv3],\n",
    "      kernel=(3,3), pad=(1,1), n_filter=384, n_group=2, neuron=Neurons.ReLU())\n",
    "  ConvolutionLayer(name=\"conv5\", tops=[:conv5], bottoms=[:conv4],\n",
    "      kernel=(3,3), pad=(1,1), n_filter=256, n_group=2, neuron=Neurons.ReLU())\n",
    "  PoolingLayer(name=\"pool5\", tops=[:pool5], bottoms=[:conv5],\n",
    "      kernel=(3,3), stride=(2,2), pooling=Pooling.Max())\n",
    "  InnerProductLayer(name=\"fc6\", tops=[:fc6], bottoms=[:pool5],\n",
    "      output_dim=4096, neuron=Neurons.ReLU())\n",
    "  InnerProductLayer(name=\"fc7\", tops=[:fc7], bottoms=[:fc6],\n",
    "      output_dim=4096, neuron=Neurons.ReLU())\n",
    "  InnerProductLayer(name=\"fc8\", tops=[:fc8], bottoms=[:fc7],\n",
    "      output_dim=1000)\n",
    "  SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:fc8])\n",
    "]\n",
    "\n",
    "net = Net(\"imagenet\", backend, layers)\n",
    "println(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"net.dot\", \"w\") do out net2dot(out, net) end\n",
    "run(pipeline(`dot -Tpng net.dot`, \"net.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "  * `load(filename)` loads the contents of a formatted file, trying to infer\n",
       "\n",
       "the format from `filename` and/or magic bytes in the file.\n",
       "\n",
       "  * `load(strm)` loads from an `IOStream` or similar object. In this case,\n",
       "\n",
       "there is no filename extension, so we rely on the magic bytes for format identification.\n",
       "\n",
       "  * `load(File(format\"PNG\", filename))` specifies the format directly, and bypasses inference.\n",
       "  * `load(Stream(format\"PNG\", io))` specifies the format directly, and bypasses inference.\n",
       "  * `load(f; options...)` passes keyword arguments on to the loader.\n"
      ],
      "text/plain": [
       "  * `load(filename)` loads the contents of a formatted file, trying to infer\n",
       "\n",
       "the format from `filename` and/or magic bytes in the file.\n",
       "\n",
       "  * `load(strm)` loads from an `IOStream` or similar object. In this case,\n",
       "\n",
       "there is no filename extension, so we rely on the magic bytes for format identification.\n",
       "\n",
       "  * `load(File(format\"PNG\", filename))` specifies the format directly, and bypasses inference.\n",
       "  * `load(Stream(format\"PNG\", io))` specifies the format directly, and bypasses inference.\n",
       "  * `load(f; options...)` passes keyword arguments on to the loader.\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Images.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
